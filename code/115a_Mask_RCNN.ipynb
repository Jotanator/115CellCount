{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "115a_Mask_RCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "66njXV8vSF4S",
        "pnNDg13MSF4f"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBBoE7WnSF4M"
      },
      "source": [
        "# Mask R-CNN Notebook for Cell Counting Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5ktg1Uge34-"
      },
      "source": [
        "## Prerequisites to running\n",
        "\n",
        "ALWAYS run the following 2 cells. Make sure to check that you are on a GPU runtime. If you intend on using something else, make sure to change the second cell's DEVICE to reflect that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQA7xkdqO4jI"
      },
      "source": [
        "# Prereqs to running\n",
        "# Always run this cell first\n",
        "\n",
        "!pip install q keras==2.0.8\n",
        "!pip install q keras==2.2.5\n",
        "%tensorflow_version 1.x\n",
        "!pip install q h5py==2.10.0\n",
        "!rm -r sample_data/\n",
        "!git clone https://github.com/Jotanator/115CellCount\n",
        "%cd 115CellCount/MASK-R-CNN\n",
        "!rm ../mask_rcnn_balloon_0030.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AWFFD7ESF4O"
      },
      "source": [
        "# Always run this cell second\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\".\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "from mrcnn import visualize\n",
        "from mrcnn.visualize import display_images\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn.model import log\n",
        "\n",
        "#from samples.balloon\n",
        "import balloon\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"../logs\")\n",
        "#print(MODEL_DIR)\n",
        "\n",
        "# Path to balloon data folder that contains train/ and val/\n",
        "config = balloon.BalloonConfig()\n",
        "BALLOON_DIR = os.path.join(ROOT_DIR, \"data\")\n",
        "#print(BALLOON_DIR)\n",
        "\n",
        "class InferenceConfig(config.__class__):\n",
        "    # Run detection on one image at a time\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "config = InferenceConfig()\n",
        "#config.display()\n",
        "\n",
        "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
        "\n",
        "TEST_MODE = \"inference\"\n",
        "def get_ax(rows=1, cols=1, size=16):\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66njXV8vSF4S"
      },
      "source": [
        "## Predicting\n",
        "\n",
        "Run the below cells for running predictions on data in the val folder.\n",
        "The images you want to predict on must be included in the via_region_data.json file to be valid. You will need to manually upload the .h5 file to 115CellCount. DO NOT run the cell that loads the model until the .h5 is finished uploading or else you might corrupt it and need to redownload it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjDnuozcmt3P"
      },
      "source": [
        "# Load validation dataset\n",
        "dataset = balloon.BalloonDataset()\n",
        "dataset.load_balloon(BALLOON_DIR, \"val\")\n",
        "dataset.prepare()\n",
        "\n",
        "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p95Ag61lmyrY"
      },
      "source": [
        "# Create model in inference mode\n",
        "with tf.device(DEVICE):\n",
        "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
        "                              config=config)\n",
        "\n",
        "# Change this to whatever file you want to load\n",
        "weights_path = os.path.join(ROOT_DIR, \"../mask_rcnn_balloon_0030.h5\")\n",
        "print(weights_path)\n",
        "\n",
        "model.load_weights(weights_path, by_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3kWJahLSF4T"
      },
      "source": [
        "# Change this to any specific id you might want, or random choice\n",
        "image_id = 0\n",
        "#image_id = random.choice(dataset.image_ids)\n",
        "\n",
        "image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
        "info = dataset.image_info[image_id]\n",
        "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
        "                                       dataset.image_reference(image_id)))\n",
        "\n",
        "# Run object detection\n",
        "results = model.detect([image], verbose=1)\n",
        "\n",
        "# Display results\n",
        "ax = get_ax(1)\n",
        "r = results[0]\n",
        "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset.class_names, r['scores'], ax=ax,\n",
        "                            title=\"Predictions\")\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnNDg13MSF4f"
      },
      "source": [
        "## Training\n",
        "\n",
        "Run the below cell while current directory is inside samples/balloon. If it gives an error, try using a different keras version in the cell at the top of the notebook. You will need to restart your runtime and you will need to rerun the cells. Your files will all still be there. The models for each epoch will be put into a logs folder which will be at the same level as 115CellCount."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqTHg1Gz6Or4"
      },
      "source": [
        "#Train a new model starting from ImageNet weights\n",
        "!python3 balloon.py train --dataset=data/ --weights=imagenet\n",
        "\n",
        "#Train a new model starting from pre-trained COCO weights\n",
        "#!python3 balloon.py train --dataset=data/ --weights=coco\n",
        "\n",
        "#Resume training a model that you had trained earlier\n",
        "#!python3 balloon.py train --dataset=data/ --weights=last"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}